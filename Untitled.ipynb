{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.constraints import unitnorm\n",
    "from keras.layers.core import Reshape, Flatten, Merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "import math\n",
    "from keras_input_data import make_idx_data\n",
    "from load_vai import loadVAI\n",
    "import _pickle as cPickle\n",
    "from metrics import continuous_metrics\n",
    "from keras import backend as K\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imdb_cnn(W=None):\n",
    "    # Number of feature maps (outputs of convolutional layer)\n",
    "    N_fm = 10\n",
    "    # kernel size of convolutional layer\n",
    "    kernel_size =10\n",
    "    dims = 300  # 300 dimension\n",
    "    maxlen = 87  # maxlen of sentence\n",
    "    max_features = W.shape[0]\n",
    "    hidden_dims = 100\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    model.add(Embedding(max_features, dims, input_length=maxlen, weights=[W]))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    # we add a Convolution1D, which will learn nb_filter\n",
    "    # word group filters of size filter_length:\n",
    "    model.add(Convolution1D(nb_filter=N_fm,\n",
    "                            filter_length=kernel_size,\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            ))\n",
    "    model.add(Dropout(0.4))\n",
    "    # we use standard max pooling (halving the output of the previous layer):\n",
    "    model.add(MaxPooling1D(pool_length=1))\n",
    "\n",
    "    # We flatten the output of the conv layer,\n",
    "    # so that we can add a vanilla dense layer:\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # We add a vanilla hidden layer:\n",
    "    model.add(Dense(hidden_dims))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    print('----------- imdbcnn----------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm(W):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(W.shape[0], W.shape[1], input_length=maxlen))\n",
    "    model.add(LSTM(200))  # try using a GRU instead, for fun\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    print('----------- lstm----------')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cnn_lstm(W):\n",
    "    nb_filter = 20\n",
    "    filter_length = 3\n",
    "    pool_length = 1\n",
    "    lstm_output_size = 60\n",
    "    p = 0.5\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(W.shape[0], W.shape[1], input_length=maxlen, weights=[W]))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                            filter_length=filter_length,\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            subsample_length=1))\n",
    "    model.add(MaxPooling1D(pool_length=pool_length))\n",
    "    model.add(LSTM(lstm_output_size))\n",
    "    model.add(Dense(lstm_output_size))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    print('----------- cnnlstm----------')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cnn(W):\n",
    "    \n",
    "    nb_filter = 10\n",
    "    filter_length =2\n",
    "    pool_length = 1\n",
    "    \n",
    "    region_input = Input(shape=(maxlen,), dtype='int32', name='region_input')\n",
    "        ###这是一个逗号标志的输入的区域的句子，属于整个文章的一个区域。\n",
    "    x = Embedding(W.shape[0], W.shape[1], weights=[W], input_length=maxlen)(region_input)\n",
    "\n",
    "    lstm_output = LSTM(50, return_sequences=True, name='lstm')(x)  \n",
    "\n",
    "    region_conv = Convolution1D(nb_filter=nb_filter,\n",
    "                                    filter_length=filter_length,\n",
    "                                    border_mode='valid',\n",
    "                                    activation='relu',\n",
    "                                    subsample_length=1)(lstm_output)\n",
    "    region_max = MaxPooling1D(pool_length=pool_length)(region_conv)\n",
    "    region_vector = Flatten()(region_max)\n",
    "    textvector = Dense(30, activation='relu')(region_vector)\n",
    "    predictions = Dense(1, activation='linear')(textvector)\n",
    "    final_model = Model(region_input, predictions, name='model')\n",
    "    model=final_model\n",
    "    print('----------- lstmcnn----------')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n",
      "------------- now is irony1005------------\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1020 - val_loss: 0.5751\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5719 - val_loss: 0.7219\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4743 - val_loss: 0.6249\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4280 - val_loss: 0.5716\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3672 - val_loss: 0.6508\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3189 - val_loss: 0.5625\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2996 - val_loss: 0.5500\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2711 - val_loss: 0.6175\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2543 - val_loss: 0.5657\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2378 - val_loss: 0.5691\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.3276 - val_loss: 0.6228\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5716 - val_loss: 0.5950\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4779 - val_loss: 0.5910\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4076 - val_loss: 0.5918\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3390 - val_loss: 0.5890\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3179 - val_loss: 0.5702\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2803 - val_loss: 0.5830\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2599 - val_loss: 0.5969\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2369 - val_loss: 0.5870\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2180 - val_loss: 0.5905\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1066 - val_loss: 0.9103\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.6060 - val_loss: 0.6320\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4950 - val_loss: 1.0363\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4354 - val_loss: 0.6392\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3771 - val_loss: 0.5872\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3294 - val_loss: 0.6148\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3131 - val_loss: 0.6150\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2811 - val_loss: 0.6167\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2504 - val_loss: 0.6209\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2337 - val_loss: 0.6131\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 0.9908 - val_loss: 0.6275\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5924 - val_loss: 0.6755\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5048 - val_loss: 0.5899\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4096 - val_loss: 0.6043\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3893 - val_loss: 0.5917\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3380 - val_loss: 0.5891\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3125 - val_loss: 0.5823\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2859 - val_loss: 0.5903\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2626 - val_loss: 0.6017\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2397 - val_loss: 0.6828\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1099 - val_loss: 0.7859\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.6087 - val_loss: 0.7623\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5246 - val_loss: 0.5143\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4454 - val_loss: 0.8286\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3830 - val_loss: 0.6957\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3387 - val_loss: 0.5673\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3047 - val_loss: 0.6325\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2852 - val_loss: 0.5134\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2521 - val_loss: 0.5160\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2410 - val_loss: 0.5253\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.596 0.285\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0734 - val_loss: 0.5249\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5659 - val_loss: 0.6254\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4997 - val_loss: 0.5466\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4329 - val_loss: 0.4977\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3952 - val_loss: 0.5228\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3353 - val_loss: 0.6172\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3004 - val_loss: 0.5447\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2769 - val_loss: 0.6816\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2550 - val_loss: 0.5422\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2335 - val_loss: 0.5348\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.2024 - val_loss: 0.7320\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5903 - val_loss: 0.6454\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5056 - val_loss: 0.6114\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4372 - val_loss: 0.5742\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3804 - val_loss: 0.5811\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3439 - val_loss: 0.5687\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3023 - val_loss: 0.6165\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2737 - val_loss: 0.6135\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2575 - val_loss: 0.6777\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2408 - val_loss: 0.5886\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0198 - val_loss: 0.9139\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5619 - val_loss: 0.5472\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4706 - val_loss: 0.5541\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.3870 - val_loss: 0.6946\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3408 - val_loss: 0.5614\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3058 - val_loss: 0.6489\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2769 - val_loss: 0.6759\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2561 - val_loss: 0.5982\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 0.9876 - val_loss: 1.0462\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.6076 - val_loss: 0.7078\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5109 - val_loss: 0.5782\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4371 - val_loss: 0.6301\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3701 - val_loss: 0.8091\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3421 - val_loss: 0.7312\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2939 - val_loss: 0.6285\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2699 - val_loss: 0.6247\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2541 - val_loss: 0.6173\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1055 - val_loss: 0.5657\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5586 - val_loss: 0.7467\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5188 - val_loss: 0.7403\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4274 - val_loss: 0.5930\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3786 - val_loss: 0.5660\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3396 - val_loss: 0.5847\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3011 - val_loss: 0.6930\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.606 0.29\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.2337 - val_loss: 0.8421\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5920 - val_loss: 0.5735\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5051 - val_loss: 0.5680\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4345 - val_loss: 0.6532\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3984 - val_loss: 0.5622\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3452 - val_loss: 0.5663\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3137 - val_loss: 0.8343\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.3051 - val_loss: 0.5952\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2687 - val_loss: 0.6693\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2417 - val_loss: 0.5990\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1857 - val_loss: 0.8806\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5992 - val_loss: 0.6033\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5220 - val_loss: 0.6131\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4596 - val_loss: 0.5559\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.4000 - val_loss: 0.5234\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3574 - val_loss: 0.6180\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3212 - val_loss: 0.5340\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2938 - val_loss: 0.5772\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2728 - val_loss: 0.5355\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2725 - val_loss: 0.5352\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1193 - val_loss: 0.5605\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5965 - val_loss: 0.5344\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4779 - val_loss: 0.6398\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4374 - val_loss: 0.5906\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3849 - val_loss: 0.7814\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3351 - val_loss: 0.6537\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3113 - val_loss: 0.5775\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2763 - val_loss: 0.7268\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0618 - val_loss: 0.5548\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.6196 - val_loss: 0.7440\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5138 - val_loss: 0.6216\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4482 - val_loss: 0.7131\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3841 - val_loss: 0.6218\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3598 - val_loss: 0.5915\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3241 - val_loss: 0.5740\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1104 - val_loss: 0.6692\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5479 - val_loss: 0.5591\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4847 - val_loss: 0.6031\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4209 - val_loss: 0.5792\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3664 - val_loss: 0.6223\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3222 - val_loss: 0.6532\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2849 - val_loss: 0.7085\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2523 - val_loss: 0.6329\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.614 0.3\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1372 - val_loss: 0.9681\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.6063 - val_loss: 0.5489\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5355 - val_loss: 0.7356\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4509 - val_loss: 0.6039\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3772 - val_loss: 0.6072\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3420 - val_loss: 0.7596\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3048 - val_loss: 0.7324\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2863 - val_loss: 0.6189\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0839 - val_loss: 0.5808\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5710 - val_loss: 0.8287\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4875 - val_loss: 0.5881\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4195 - val_loss: 0.5881\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3702 - val_loss: 0.5934\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3336 - val_loss: 0.7057\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3028 - val_loss: 0.5797\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2718 - val_loss: 0.5844\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2622 - val_loss: 0.6397\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2482 - val_loss: 0.7200\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0056 - val_loss: 0.7454\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5806 - val_loss: 0.7395\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 6s - loss: 0.4887 - val_loss: 0.6718\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4100 - val_loss: 0.5414\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3634 - val_loss: 0.5309\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3233 - val_loss: 0.5271\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3027 - val_loss: 0.5274\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2787 - val_loss: 0.5492\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2504 - val_loss: 0.5282\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2346 - val_loss: 0.5308\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0533 - val_loss: 0.6073\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5570 - val_loss: 0.8608\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.4962 - val_loss: 0.5921\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4322 - val_loss: 0.5925\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3790 - val_loss: 0.6043\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3249 - val_loss: 0.5588\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2936 - val_loss: 0.5784\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2785 - val_loss: 0.5812\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2526 - val_loss: 0.5809\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2318 - val_loss: 0.5905\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1770 - val_loss: 0.6621\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5595 - val_loss: 0.7069\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5022 - val_loss: 0.5878\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4372 - val_loss: 0.6817\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3912 - val_loss: 0.5608\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3393 - val_loss: 0.6141\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3133 - val_loss: 0.5747\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2920 - val_loss: 0.5944\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2685 - val_loss: 0.6037\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2368 - val_loss: 0.5644\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.605 0.295\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0855 - val_loss: 0.5823\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5723 - val_loss: 0.5356\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5047 - val_loss: 0.5449\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4349 - val_loss: 0.6532\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3783 - val_loss: 0.5993\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3256 - val_loss: 0.5762\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2805 - val_loss: 0.5993\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2735 - val_loss: 0.5733\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0401 - val_loss: 0.6549\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5747 - val_loss: 0.6079\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5068 - val_loss: 0.5714\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4372 - val_loss: 0.7956\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3629 - val_loss: 0.7038\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3355 - val_loss: 0.6130\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.2937 - val_loss: 0.6251\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2606 - val_loss: 0.7217\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2532 - val_loss: 0.6747\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.1084 - val_loss: 1.0557\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5816 - val_loss: 0.6000\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5051 - val_loss: 0.7611\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4396 - val_loss: 0.6199\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3946 - val_loss: 0.6295\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3384 - val_loss: 0.6065\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3138 - val_loss: 0.5693\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2941 - val_loss: 0.5800\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2570 - val_loss: 0.6241\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2454 - val_loss: 0.5850\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0772 - val_loss: 0.5826\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5928 - val_loss: 0.5359\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5037 - val_loss: 0.5439\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4505 - val_loss: 0.5328\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3898 - val_loss: 0.5217\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3436 - val_loss: 0.5146\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3202 - val_loss: 0.5239\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2778 - val_loss: 0.5129\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2491 - val_loss: 0.5881\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2334 - val_loss: 0.5230\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 5s - loss: 1.0903 - val_loss: 0.5585\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 5s - loss: 0.5944 - val_loss: 0.7105\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 5s - loss: 0.5167 - val_loss: 0.6674\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 5s - loss: 0.4279 - val_loss: 0.5730\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 5s - loss: 0.3886 - val_loss: 0.5486\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 5s - loss: 0.3524 - val_loss: 0.5726\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 5s - loss: 0.3082 - val_loss: 0.5625\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 5s - loss: 0.2788 - val_loss: 0.6115\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 5s - loss: 0.2628 - val_loss: 0.5718\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 5s - loss: 0.2480 - val_loss: 0.5716\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.586 0.269\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    x = cPickle.load(open(\"mr.p\", \"rb\"))\n",
    "    revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]\n",
    "    print(\"data loaded!\")\n",
    "    sentences=[]\n",
    "    for rev in revs:\n",
    "        sentence = rev['text']\n",
    "        sentences.append(sentence)\n",
    "    idx_data = make_idx_data(sentences, word_idx_map)\n",
    "    #print(idx_data)\n",
    "\n",
    "    dim = 'I'\n",
    "    column = loadVAI(dim)\n",
    "    irony=column\n",
    "    maxlen = 87  # cut texts after this number of words (among top max_features most common words)\n",
    "    batch_size = 8\n",
    "\n",
    "    # option = 'Irony'  # or Arousal,irony\n",
    "    Y = np.array(irony)\n",
    "    Y = [float(x) for x in Y]\n",
    "    # print(option + ' prediction.......................')\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = cross_validation.train_test_split(idx_data, Y, test_size=0.2,\n",
    "    #                                                                      random_state=2)\n",
    "    n_MAE=0\n",
    "    n_Pearson_r=0\n",
    "    n_Spearman_r=0\n",
    "    n_MSE=0\n",
    "    n_R2=0\n",
    "    n_MSE_sqrt=0\n",
    "    SEED = 42\n",
    "    ID=list(range(1,1006))\n",
    "    n = 5  # repeat the CV procedure 5 times to get more precise results\n",
    "   \n",
    "    X_train_0, X_test_0, y_train_0, y_test_0, ID_train_0, ID_test_0 = cross_validation.train_test_split(\n",
    "         idx_data, Y, ID, test_size=.20, random_state=2)\n",
    "    j=0\n",
    "    for i in range(n):\n",
    "        n_MAE=0\n",
    "        n_Pearson_r=0\n",
    "       \n",
    "        for i in range(n):\n",
    "            # for each iteration, randomly hold out 20% of the data as CV set\n",
    "            # X_train, X_test, y_train, y_test, ID_train, ID_test = cross_validation.train_test_split(\n",
    "            #     idx_data, Y, ID, test_size=.20, random_state=i * SEED)\n",
    "            y_test = y_test_0\n",
    "            y_train = y_train_0\n",
    "            X_test = X_test_0\n",
    "            X_train = X_train_0\n",
    "            ID_test = ID_test_0\n",
    "            ID_train = ID_train_0\n",
    "            if i>0:\n",
    "                y_test=y_train_0[:201]\n",
    "                y_train=y_train_0[201:]+y_test_0\n",
    "                X_test = X_train_0[:201]\n",
    "                X_train=X_train_0[201:]+X_test_0\n",
    "                ID_test = ID_train_0[:201]\n",
    "                ID_train = ID_train_0[201:]+ID_test_0\n",
    "                y_test_0 = y_test\n",
    "                y_train_0 = y_train\n",
    "                X_test_0 = X_test\n",
    "                X_train_0 = X_train\n",
    "                ID_test_0 = ID_test\n",
    "                ID_train_0 = ID_train\n",
    "\n",
    "            max_features = W.shape[0]  # shape of W: (13631, 300) , changed to 14027 through min_df = 3\n",
    "            # print(max_features)\n",
    "\n",
    "            #print(\"Pad sequences (samples x time)\")\n",
    "            X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "            X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "            #print('X_train shape:', X_train.shape)\n",
    "            #print('X_test shape:', X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "            model = lstm_cnn(W)\n",
    "\n",
    "            model.compile(loss='mae', optimizer='adagrad')  # loss function: mse\n",
    "            #print(\"Train...\")\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            result = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10,validation_data=(X_test, y_test),\n",
    "                               callbacks=[early_stopping])\n",
    "            score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "            #print('Test score:', score)\n",
    "            # experiment evaluated by multiple metrics\n",
    "            predict = model.predict(X_test, batch_size=batch_size).reshape((1, len(X_test)))[0]\n",
    "            #print(ID_test)\n",
    "            predict=list(predict)\n",
    "            #print(list(predict))\n",
    "            headers=['ID_test','pred']\n",
    "            with open('./irony_1005_2/I_lstmcnn'+str(j+1)+'_prediction.csv','a+',newline='') as f:\n",
    "                    write = csv.writer(f)\n",
    "                    write.writerow(headers)\n",
    "                    for i in range(0,201):\n",
    "                        write.writerow([ID_test[i],predict[i]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            estimate=continuous_metrics(y_test, predict, 'prediction result:')\n",
    "             # MSE, MAE, Pearson_r, R2, Spearman_r, MSE_sqrt\n",
    "\n",
    "            n_MAE += estimate[0]\n",
    "            n_Pearson_r += estimate[1]\n",
    "\n",
    "        ndigit=3\n",
    "\n",
    "        avg_MAE =  round(n_MAE/5, ndigit)\n",
    "        avg_Pearson_r =  round(n_Pearson_r/5, ndigit) \n",
    "\n",
    "        print('average evaluate result:')\n",
    "        print(avg_MAE ,avg_Pearson_r)\n",
    "        j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py34]",
   "language": "python",
   "name": "conda-env-py34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
