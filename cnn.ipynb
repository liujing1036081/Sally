{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.constraints import unitnorm\n",
    "from keras.layers.core import Reshape, Flatten, Merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution1D, MaxPooling1D\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "import math\n",
    "from keras_input_data import make_idx_data\n",
    "from load_vai import loadVAI\n",
    "import _pickle as cPickle\n",
    "from metrics import continuous_metrics\n",
    "from keras import backend as K\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imdb_cnn(W=None):\n",
    "    # Number of feature maps (outputs of convolutional layer)\n",
    "    N_fm = 10\n",
    "    # kernel size of convolutional layer\n",
    "    kernel_size =10\n",
    "    dims = 300  # 300 dimension\n",
    "    maxlen = 87  # maxlen of sentence\n",
    "    max_features = W.shape[0]\n",
    "    hidden_dims = 100\n",
    "    print('Build model...')\n",
    "    model = Sequential()\n",
    "\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    model.add(Embedding(max_features, dims, input_length=maxlen, weights=[W]))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    # we add a Convolution1D, which will learn nb_filter\n",
    "    # word group filters of size filter_length:\n",
    "    model.add(Convolution1D(nb_filter=N_fm,\n",
    "                            filter_length=kernel_size,\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            ))\n",
    "    model.add(Dropout(0.4))\n",
    "    # we use standard max pooling (halving the output of the previous layer):\n",
    "    model.add(MaxPooling1D(pool_length=1))\n",
    "\n",
    "    # We flatten the output of the conv layer,\n",
    "    # so that we can add a vanilla dense layer:\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # We add a vanilla hidden layer:\n",
    "    model.add(Dense(hidden_dims))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    print('----------- imdbcnn----------')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm(W):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(W.shape[0], W.shape[1], input_length=maxlen))\n",
    "    model.add(LSTM(200))  # try using a GRU instead, for fun\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    print('----------- lstm----------')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cnn_lstm(W):\n",
    "    nb_filter = 20\n",
    "    filter_length = 3\n",
    "    pool_length = 1\n",
    "    lstm_output_size = 60\n",
    "    p = 0.5\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(W.shape[0], W.shape[1], input_length=maxlen, weights=[W]))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                            filter_length=filter_length,\n",
    "                            border_mode='valid',\n",
    "                            activation='relu',\n",
    "                            subsample_length=1))\n",
    "    model.add(MaxPooling1D(pool_length=pool_length))\n",
    "    model.add(LSTM(lstm_output_size))\n",
    "    model.add(Dense(lstm_output_size))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('linear'))\n",
    "    print('----------- cnnlstm----------')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cnn(W):\n",
    "    \n",
    "    nb_filter = 10\n",
    "    filter_length =2\n",
    "    pool_length = 1\n",
    "    \n",
    "    region_input = Input(shape=(maxlen,), dtype='int32', name='region_input')\n",
    "        ###这是一个逗号标志的输入的区域的句子，属于整个文章的一个区域。\n",
    "    x = Embedding(W.shape[0], W.shape[1], weights=[W], input_length=maxlen)(region_input)\n",
    "\n",
    "    lstm_output = LSTM(50, return_sequences=True, name='lstm')(x)  \n",
    "\n",
    "    region_conv = Convolution1D(nb_filter=nb_filter,\n",
    "                                    filter_length=filter_length,\n",
    "                                    border_mode='valid',\n",
    "                                    activation='relu',\n",
    "                                    subsample_length=1)(lstm_output)\n",
    "    region_max = MaxPooling1D(pool_length=pool_length)(region_conv)\n",
    "    region_vector = Flatten()(region_max)\n",
    "    textvector = Dense(30, activation='relu')(region_vector)\n",
    "    predictions = Dense(1, activation='linear')(textvector)\n",
    "    final_model = Model(region_input, predictions, name='model')\n",
    "    model=final_model\n",
    "    print('----------- lstmcnn----------')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded!\n",
      "--------------- now is valence1005------------\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7022 - val_loss: 0.4959\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4056 - val_loss: 0.5610\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3541 - val_loss: 0.3996\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3269 - val_loss: 0.3934\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2841 - val_loss: 0.3789\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2515 - val_loss: 0.4513\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2277 - val_loss: 0.3980\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 6s - loss: 0.1916 - val_loss: 0.4117\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1755 - val_loss: 0.3932\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 7s - loss: 0.1587 - val_loss: 0.4074\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8443 - val_loss: 0.4378\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4099 - val_loss: 0.4593\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3248 - val_loss: 0.6500\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.2875 - val_loss: 0.3797\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2523 - val_loss: 0.3985\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2155 - val_loss: 0.4183\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.1984 - val_loss: 0.4140\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 6s - loss: 0.1737 - val_loss: 0.3890\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1590 - val_loss: 0.4066\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 7s - loss: 0.1545 - val_loss: 0.3902\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8021 - val_loss: 0.3773\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4018 - val_loss: 0.4425\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3536 - val_loss: 0.5620\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3017 - val_loss: 0.3987\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2602 - val_loss: 0.4301\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2345 - val_loss: 0.3921\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2089 - val_loss: 0.4123\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.6878 - val_loss: 0.4128\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4125 - val_loss: 0.3872\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3631 - val_loss: 0.4439\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3213 - val_loss: 0.4051\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2857 - val_loss: 0.4696\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2443 - val_loss: 0.4147\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2162 - val_loss: 0.4129\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1942 - val_loss: 0.4092\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 8s - loss: 0.7814 - val_loss: 0.5808\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4092 - val_loss: 0.3782\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3561 - val_loss: 0.4357\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3122 - val_loss: 0.5892\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2624 - val_loss: 0.3854\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2325 - val_loss: 0.3924\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2088 - val_loss: 0.4025\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.2057 - val_loss: 0.3863\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.401 0.323\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 8s - loss: 0.6911 - val_loss: 0.3775\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.3788 - val_loss: 0.4505\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 8s - loss: 0.3501 - val_loss: 0.4197\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.2999 - val_loss: 0.3910\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 8s - loss: 0.2627 - val_loss: 0.3798\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2381 - val_loss: 0.3796\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2172 - val_loss: 0.3865\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7547 - val_loss: 0.3857\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.3973 - val_loss: 0.4754\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3431 - val_loss: 0.3913\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3116 - val_loss: 0.3952\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 8s - loss: 0.2653 - val_loss: 0.4643\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 8s - loss: 0.2379 - val_loss: 0.3983\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2085 - val_loss: 0.3955\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8189 - val_loss: 0.5499\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4060 - val_loss: 0.3742\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3609 - val_loss: 0.3595\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3026 - val_loss: 0.4004\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2482 - val_loss: 0.3687\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2209 - val_loss: 0.3952\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 8s - loss: 0.2001 - val_loss: 0.4114\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1806 - val_loss: 0.3875\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1635 - val_loss: 0.4779\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7799 - val_loss: 0.4826\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4123 - val_loss: 0.3794\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 6s - loss: 0.3455 - val_loss: 0.4412\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3125 - val_loss: 0.3774\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2587 - val_loss: 0.3861\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 8s - loss: 0.2286 - val_loss: 0.4545\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2073 - val_loss: 0.3816\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1873 - val_loss: 0.4014\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1687 - val_loss: 0.3890\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 7s - loss: 0.1517 - val_loss: 0.3864\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8120 - val_loss: 0.9478\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4219 - val_loss: 0.4862\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 6s - loss: 0.3550 - val_loss: 0.3929\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 6s - loss: 0.3021 - val_loss: 0.5081\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2759 - val_loss: 0.4416\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2396 - val_loss: 0.4064\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2117 - val_loss: 0.4196\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.2064 - val_loss: 0.3969\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1821 - val_loss: 0.4138\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.412 0.324\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7633 - val_loss: 0.3834\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4314 - val_loss: 0.4317\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3710 - val_loss: 0.4318\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3326 - val_loss: 0.4013\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 6s - loss: 0.2762 - val_loss: 0.3984\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2554 - val_loss: 0.3922\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2283 - val_loss: 0.3876\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8121 - val_loss: 0.4086\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 8s - loss: 0.3934 - val_loss: 0.5699\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 8s - loss: 0.3484 - val_loss: 0.3893\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.2928 - val_loss: 0.4002\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2500 - val_loss: 0.4314\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2254 - val_loss: 0.4555\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2034 - val_loss: 0.4428\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1846 - val_loss: 0.3895\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1728 - val_loss: 0.3919\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7370 - val_loss: 0.6495\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.3966 - val_loss: 0.3835\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 8s - loss: 0.3478 - val_loss: 0.3856\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3066 - val_loss: 0.4162\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2562 - val_loss: 0.3966\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2184 - val_loss: 0.4464\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.1932 - val_loss: 0.4004\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1688 - val_loss: 0.4025\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7286 - val_loss: 0.4475\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.3937 - val_loss: 0.4372\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3412 - val_loss: 0.3621\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.2981 - val_loss: 0.4019\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2722 - val_loss: 0.4333\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2223 - val_loss: 0.4427\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2058 - val_loss: 0.3855\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1831 - val_loss: 0.3746\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1634 - val_loss: 0.3865\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8089 - val_loss: 0.3698\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4210 - val_loss: 0.4101\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 8s - loss: 0.3720 - val_loss: 0.5281\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3202 - val_loss: 0.6280\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2761 - val_loss: 0.5772\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2428 - val_loss: 0.4805\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2108 - val_loss: 0.3726\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.388 0.325\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8386 - val_loss: 0.4229\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4113 - val_loss: 0.3747\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3778 - val_loss: 0.4309\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 8s - loss: 0.3057 - val_loss: 0.4262\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2718 - val_loss: 0.3839\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2433 - val_loss: 0.3844\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2201 - val_loss: 0.4485\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 8s - loss: 0.2025 - val_loss: 0.4316\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7665 - val_loss: 0.5604\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4198 - val_loss: 0.4194\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 8s - loss: 0.3671 - val_loss: 0.3954\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3098 - val_loss: 0.4321\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2809 - val_loss: 0.4209\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2483 - val_loss: 0.4097\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 8s - loss: 0.2181 - val_loss: 0.3981\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 8s - loss: 0.2001 - val_loss: 0.4491\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1872 - val_loss: 0.4206\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7790 - val_loss: 0.4168\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 6s - loss: 0.4011 - val_loss: 0.4505\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 6s - loss: 0.3479 - val_loss: 0.5168\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 8s - loss: 0.3027 - val_loss: 0.4696\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 8s - loss: 0.2521 - val_loss: 0.4668\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2210 - val_loss: 0.3803\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 8s - loss: 0.1973 - val_loss: 0.3904\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 8s - loss: 0.1780 - val_loss: 0.4274\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 8s - loss: 0.1586 - val_loss: 0.3996\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 8s - loss: 0.1492 - val_loss: 0.4224\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7548 - val_loss: 0.3936\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 8s - loss: 0.3863 - val_loss: 0.4692\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3529 - val_loss: 0.4245\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.2952 - val_loss: 0.4178\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 8s - loss: 0.2454 - val_loss: 0.4248\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 8s - loss: 0.2123 - val_loss: 0.4295\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.1886 - val_loss: 0.4078\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.6749 - val_loss: 0.3624\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 8s - loss: 0.4213 - val_loss: 0.4106\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3611 - val_loss: 0.4122\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3250 - val_loss: 0.4340\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 8s - loss: 0.2839 - val_loss: 0.3965\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2612 - val_loss: 0.3864\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2327 - val_loss: 0.3968\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.416 0.281\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8257 - val_loss: 0.3741\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 8s - loss: 0.4160 - val_loss: 0.4948\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3414 - val_loss: 0.4893\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3182 - val_loss: 0.3797\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2646 - val_loss: 0.5012\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2281 - val_loss: 0.4931\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 8s - loss: 0.2237 - val_loss: 0.3830\n",
      "201/201 [==============================] - 0s     \n",
      "MAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.8171 - val_loss: 0.5315\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4027 - val_loss: 0.4154\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3366 - val_loss: 0.4446\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 8s - loss: 0.2957 - val_loss: 0.3819\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 8s - loss: 0.2447 - val_loss: 0.4173\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 8s - loss: 0.2178 - val_loss: 0.4597\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 8s - loss: 0.1825 - val_loss: 0.3966\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1628 - val_loss: 0.3955\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1579 - val_loss: 0.4167\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 8s - loss: 0.1385 - val_loss: 0.4344\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7390 - val_loss: 0.4511\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4058 - val_loss: 0.5056\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3669 - val_loss: 0.4030\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3221 - val_loss: 0.4061\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2799 - val_loss: 0.3983\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2470 - val_loss: 0.4032\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 8s - loss: 0.2148 - val_loss: 0.3980\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1934 - val_loss: 0.3961\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1672 - val_loss: 0.4399\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 8s - loss: 0.1630 - val_loss: 0.4254\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7414 - val_loss: 0.4148\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.3895 - val_loss: 0.4634\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3407 - val_loss: 0.4090\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3066 - val_loss: 0.4286\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2579 - val_loss: 0.3917\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2336 - val_loss: 0.4583\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2065 - val_loss: 0.3831\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1871 - val_loss: 0.4105\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1715 - val_loss: 0.3981\n",
      "Epoch 10/10\n",
      "804/804 [==============================] - 7s - loss: 0.1626 - val_loss: 0.4117\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "----------- lstmcnn----------\n",
      "Train on 804 samples, validate on 201 samples\n",
      "Epoch 1/10\n",
      "804/804 [==============================] - 7s - loss: 0.7257 - val_loss: 0.6175\n",
      "Epoch 2/10\n",
      "804/804 [==============================] - 7s - loss: 0.4022 - val_loss: 0.3871\n",
      "Epoch 3/10\n",
      "804/804 [==============================] - 7s - loss: 0.3708 - val_loss: 0.3793\n",
      "Epoch 4/10\n",
      "804/804 [==============================] - 7s - loss: 0.3268 - val_loss: 0.3905\n",
      "Epoch 5/10\n",
      "804/804 [==============================] - 7s - loss: 0.2742 - val_loss: 0.4989\n",
      "Epoch 6/10\n",
      "804/804 [==============================] - 7s - loss: 0.2487 - val_loss: 0.3893\n",
      "Epoch 7/10\n",
      "804/804 [==============================] - 7s - loss: 0.2053 - val_loss: 0.4330\n",
      "Epoch 8/10\n",
      "804/804 [==============================] - 7s - loss: 0.1808 - val_loss: 0.4046\n",
      "Epoch 9/10\n",
      "804/804 [==============================] - 7s - loss: 0.1734 - val_loss: 0.4076\n",
      "200/201 [============================>.] - ETA: 0sMAE, Pearson_r\n",
      "average evaluate result:\n",
      "0.412 0.31\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    x = cPickle.load(open(\"mr.p\", \"rb\"))\n",
    "    revs, W, W2, word_idx_map, vocab = x[0], x[1], x[2], x[3], x[4]\n",
    "    print(\"data loaded!\")\n",
    "    sentences=[]\n",
    "    for rev in revs:\n",
    "        sentence = rev['text']\n",
    "        sentences.append(sentence)\n",
    "    idx_data = make_idx_data(sentences, word_idx_map)\n",
    "    #print(idx_data)\n",
    "\n",
    "    dim = 'V'\n",
    "    column = loadVAI(dim)\n",
    "    irony=column\n",
    "    maxlen = 87  # cut texts after this number of words (among top max_features most common words)\n",
    "    batch_size = 8\n",
    "\n",
    "    # option = 'Irony'  # or Arousal,irony\n",
    "    Y = np.array(irony)\n",
    "    Y = [float(x) for x in Y]\n",
    "    # print(option + ' prediction.......................')\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = cross_validation.train_test_split(idx_data, Y, test_size=0.2,\n",
    "    #                                                                      random_state=2)\n",
    "    n_MAE=0\n",
    "    n_Pearson_r=0\n",
    "    n_Spearman_r=0\n",
    "    n_MSE=0\n",
    "    n_R2=0\n",
    "    n_MSE_sqrt=0\n",
    "    SEED = 42\n",
    "    ID=list(range(1,1006))\n",
    "    n = 5  # repeat the CV procedure 5 times to get more precise results\n",
    "    \n",
    "    X_train_0, X_test_0, y_train_0, y_test_0, ID_train_0, ID_test_0 = cross_validation.train_test_split(\n",
    "         idx_data, Y, ID, test_size=.20, random_state=2)\n",
    "    j=0\n",
    "    for i in range(n):\n",
    "        n_MAE=0\n",
    "        n_Pearson_r=0\n",
    "        \n",
    "        for i in range(n):\n",
    "            # for each iteration, randomly hold out 20% of the data as CV set\n",
    "            # X_train, X_test, y_train, y_test, ID_train, ID_test = cross_validation.train_test_split(\n",
    "            #     idx_data, Y, ID, test_size=.20, random_state=i * SEED)\n",
    "            y_test = y_test_0\n",
    "            y_train = y_train_0\n",
    "            X_test = X_test_0\n",
    "            X_train = X_train_0\n",
    "            ID_test = ID_test_0\n",
    "            ID_train = ID_train_0\n",
    "            if i>0:\n",
    "                y_test=y_train_0[:201]\n",
    "                y_train=y_train_0[201:]+y_test_0\n",
    "                X_test = X_train_0[:201]\n",
    "                X_train=X_train_0[201:]+X_test_0\n",
    "                ID_test = ID_train_0[:201]\n",
    "                ID_train = ID_train_0[201:]+ID_test_0\n",
    "                y_test_0 = y_test\n",
    "                y_train_0 = y_train\n",
    "                X_test_0 = X_test\n",
    "                X_train_0 = X_train\n",
    "                ID_test_0 = ID_test\n",
    "                ID_train_0 = ID_train\n",
    "\n",
    "            max_features = W.shape[0]  # shape of W: (13631, 300) , changed to 14027 through min_df = 3\n",
    "            # print(max_features)\n",
    "\n",
    "            #print(\"Pad sequences (samples x time)\")\n",
    "            X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "            X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "            #print('X_train shape:', X_train.shape)\n",
    "            #print('X_test shape:', X_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "            model = lstm_cnn(W)\n",
    "\n",
    "            model.compile(loss='mae', optimizer='adagrad')  # loss function: mse\n",
    "            #print(\"Train...\")\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "            result = model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=10,validation_data=(X_test, y_test),\n",
    "                               callbacks=[early_stopping])\n",
    "            score = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
    "            #print('Test score:', score)\n",
    "            # experiment evaluated by multiple metrics\n",
    "            predict = model.predict(X_test, batch_size=batch_size).reshape((1, len(X_test)))[0]\n",
    "            #print(ID_test)\n",
    "            predict=list(predict)\n",
    "            #print(list(predict))\n",
    "            headers=['ID_test','pred']\n",
    "            with open('./irony_1005_2/V_lstmcnn'+str(j+1)+'_prediction.csv','a+',newline='') as f:\n",
    "                    write = csv.writer(f)\n",
    "                    write.writerow(headers)\n",
    "                    for i in range(0,201):\n",
    "                        write.writerow([ID_test[i],predict[i]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            estimate=continuous_metrics(y_test, predict, 'prediction result:')\n",
    "             # MSE, MAE, Pearson_r, R2, Spearman_r, MSE_sqrt\n",
    "\n",
    "            n_MAE += estimate[0]\n",
    "            n_Pearson_r += estimate[1]\n",
    "\n",
    "        ndigit=3\n",
    "\n",
    "        avg_MAE =  round(n_MAE/5, ndigit)\n",
    "        avg_Pearson_r =  round(n_Pearson_r/5, ndigit) \n",
    "\n",
    "        print('average evaluate result:')\n",
    "        print(avg_MAE ,avg_Pearson_r)\n",
    "        j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py34]",
   "language": "python",
   "name": "conda-env-py34-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
